import { generateText, stepCountIs, tool } from "ai";
import { z } from "zod";
import { llamaCpp } from "ai-sdk-llama-cpp";

const model = llamaCpp({
  modelPath: "../../models/gemma-3-12b-it-Q3_K_M.gguf",
});

try {
  const result = await generateText({
    model,
    prompt: "What is the weather in Tokyo?",
    tools: {
      weather: tool({
        description: "Get the weather in a location",
        inputSchema: z.object({
          location: z.string().describe("The location to get weather for"),
        }),
        execute: async ({ location }) => ({
          location,
          temperature: 72,
        }),
      }),
    },
    stopWhen: stepCountIs(3),
  });

  console.log(result.text);
} finally {
  await model.dispose();
}
